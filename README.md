# Fake News Detection using NLP (BERT + CNN + Metadata) ğŸ“°

This project focuses on identifying **Fake News** using a hybrid deep learning approach that combines:

  * **BERT** for contextual language understanding
  * **CNN** for linguistic pattern extraction
  * **Metadata**-based source credibility scoring
  * **Ensemble fusion** for final prediction

This hybrid strategy achieves highly reliable results and minimizes misclassification.

-----

## Dataset ğŸ“š

Dataset Used: **Fake and Real News Dataset (Kaggle)**
Link: [https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)

Files included:

  * `Fake.csv`
  * `True.csv`

-----

## Features âœ¨

| Module | Description |
|--------|-------------|
| Data Preprocessing | Text cleaning, normalization, stopword removal |
| Metadata Credibility | Assigns reliability score based on news publisher |
| BERT Fine-Tuning | Learns contextual embeddings from text |
| CNN Model | Learns phrase-level and semantic patterns |
| Ensemble Model | Combines BERT + CNN predictions |
| Evaluation | Generates accuracy & classification report |

-----

## Model Performance ğŸš€

| Model | Accuracy |
|-------|---------|
| BERT + Metadata | 99.97% |
| CNN Model | 99.01% |
| Ensemble (Final) | **99.97% âœ…** |

**Classification Report:**

```
precision recall f1-score support
1.00 1.00 1.00 (7821 samples)

Overall Accuracy: 1.00
```

-----

## Project Architecture ğŸ“

```
Raw News Text
â”‚
Text Preprocessing
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               â”‚                 â”‚
BERT Model Metadata Score CNN Model
â”‚               â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Ensemble Fusion
â”‚
Fake / Real
```

-----

## How to Run (Google Colab) ğŸ’»

1.  Open the notebook:
    `Fake_News_Detection_Colab.ipynb`

2.  Set runtime to GPU:
    `Runtime` â†’ `Change runtime type` â†’ `GPU`

3.  Upload `archive.zip` dataset to Colab

4.  Run all cells in order

-----

## Requirements ğŸ“¦

  * transformers
  * torch
  * tensorflow
  * keras
  * pandas
  * numpy
  * scikit-learn
  * matplotlib

Install using:

```bash
pip install transformers torch tensorflow pandas numpy scikit-learn
```

-----

## Folder Structure ğŸ—‚ï¸

```
â”œâ”€â”€ Fake_News_Detection_Colab.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ bert_metadata_model.pt
â”‚ â””â”€â”€ cnn_fake_news_model.h5
â””â”€â”€ dataset/ (optional)
```

-----

## Conclusion

This project demonstrates an **accurate and scalable approach to Fake News Detection** by integrating NLP-based contextual modelling, pattern extraction using CNNs, and credibility-based metadata scoring. The ensemble model achieves near perfect classification performance and is suitable for real-world media validation applications.
